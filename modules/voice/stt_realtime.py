import pyaudio
import wave
import numpy as np
import webrtcvad
import collections

def record_until_silence(output_path="temp.wav", rate=16000, silence_limit=1.0):
    vad = webrtcvad.Vad(2)  # 0~3, ìˆ«ì í´ìˆ˜ë¡ ë¯¼ê°
    p = pyaudio.PyAudio()

    CHUNK = int(rate * 0.02)   # 20ms ë‹¨ìœ„
    FORMAT = pyaudio.paInt16
    CHANNELS = 1

    stream = p.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=rate,
                    input=True,
                    frames_per_buffer=CHUNK)

    print("ğŸ¤ ë§í•˜ë©´ ë…¹ìŒ ì‹œì‘ë¨... (ì¹¨ë¬µ 1ì´ˆë©´ ìë™ ì¢…ë£Œ)")

    frames = []
    silence_chunks = int(silence_limit / 0.02)
    silence_counter = 0

    while True:
        data = stream.read(CHUNK)
        frames.append(data)

        pcm = np.frombuffer(data, dtype=np.int16)
        is_speech = vad.is_speech(data, rate)

        if not is_speech:
            silence_counter += 1
        else:
            silence_counter = 0

        if silence_counter > silence_chunks:
            print("ğŸ›‘ ë§ì´ ë©ˆì¶°ì„œ ë…¹ìŒ ì¢…ë£Œë©ë‹ˆë‹¤.")
            break

    stream.stop_stream()
    stream.close()
    p.terminate()

    wf = wave.open(output_path, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(p.get_sample_size(FORMAT))
    wf.setframerate(rate)
    wf.writeframes(b"".join(frames))
    wf.close()

    return output_path
